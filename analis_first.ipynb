{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0848bb5-a77b-4e12-96d2-4920a10fac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve, \n",
    "    auc, \n",
    "    roc_auc_score,\n",
    "    precision_recall_curve, \n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import xgboost as xgb \n",
    "import lightgbm as lgb \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Balance methods \n",
    "from imblearn.over_sampling import SMOTE, ADASYN \n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "#Grafics_style \n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691532b-966d-45c0-babc-be91970725cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Dataset/Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1325a-5f9c-4640-8cbd-e4892a1364fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about data structure\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d4e670-914f-4776-8af6-77a6bcb30ba6",
   "metadata": {},
   "source": [
    "| Column | Значение |Meaning| Note|\n",
    "|---------|----------|------------|------------|\n",
    "| PIPE_NO | Серийный номер трубы | Pipe serial number | string |\n",
    "| DV_R | Напряжение правой стороны | Right side voltage | int |\n",
    "| DA_R | Ток правой стороны | Right side current | int |\n",
    "| AV_R | Среднее напряжение | Medium voltage | int |\n",
    "| AA_R | Средний ток | Average current | int |\n",
    "| PM_R | Код режима сварки | Welding mode code | int |\n",
    "| FIN_JGMT | FIN_JGMT=1: норма(normal) | FIN_JGMT=0: дефект(defect) | int |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9997f2-83b1-4c9a-bef0-2e6b6d7c4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94961504-1e9b-4030-85f2-a56377f874c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e6cf4-6e3f-47d3-a072-9f67af9cc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution (imbalance)\n",
    "\n",
    "class_counts = df['FIN_JGMT'].value_counts()\n",
    "display(class_counts)\n",
    "print(f\"Class ratio (normal:defect): {class_counts[1]/class_counts[0]:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1c2676-1b21-4319-88d0-8dbc19aa718c",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">Visualization of class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c2d35-2c3b-40e6-a320-e3fd9a77b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 5])\n",
    "ax = sns.countplot(x='FIN_JGMT', data=df, palette=['red', 'green'])\n",
    "plt.title(\"Class Distribution (0 - defect, 1 - normal)\")\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['Defect (0)', 'normal (1)'])\n",
    "\n",
    "\n",
    "total = len(df) \n",
    "for p in ax.patches: \n",
    "    height = p.get_height() \n",
    "    percentage = 100 * height / total \n",
    "    ax.annotate(f'{percentage:.1f}%', \n",
    "                (p.get_x() + p.get_width() / 2., height),\n",
    "                ha = 'center',\n",
    "                va = 'bottom', \n",
    "                fontsize=12\n",
    "                )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e033aa-08ed-4a00-ad28-59160a2c21a9",
   "metadata": {},
   "source": [
    "### <span style='color:green'> Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709db804-0a4b-4c1e-af07-4609fb02b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Data Completeness\n",
    "completeness = (1 - (df.isnull().sum() / len(df))) * 100\n",
    "display(completeness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e50958-e2b0-4a18-87b8-34e6b8ecd18e",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">As we can see, there are no empty values in our dataset.Our Dataset does not have missing values this was also checked earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad320289-50fd-4e70-ab1d-3d077eab67a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 Data Unique \n",
    "uniqueness = {}\n",
    "for col in df.columns: \n",
    "    uniqueness[col] = (df[col].nunique() / len(df)) * 100\n",
    "display(pd.Series(uniqueness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c7014e-ca0b-4be8-8a90-148c2c134eae",
   "metadata": {},
   "source": [
    "### <span style='color:red'>Outliers detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8493aa7-815b-4a21-833b-eb599fc5a956",
   "metadata": {},
   "source": [
    "#### with IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cf790-19c7-4335-878e-2ccc640ebe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_info = {} \n",
    "for col in ['DV_R', 'DA_R', 'AV_R', 'AA_R', 'PM_R']: \n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1 \n",
    "    lower_bound = Q1 - 1.5 * IQR \n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "\n",
    "    outliers_info[col] = {\n",
    "        'total_outliers': len(outliers), \n",
    "        'percentage': (len(outliers) / len(df)) * 100, \n",
    "        'min_value': df[col].min(), \n",
    "        'max_value': df[col].max(), \n",
    "        'lower_bound': lower_bound, \n",
    "        'upper_bound': upper_bound\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f86f186-3bf5-476b-8e2e-1c3c1832e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about outliers \n",
    "\n",
    "outliers_df = pd.DataFrame(outliers_info).T \n",
    "outliers_df['total_outliers'] = outliers_df['total_outliers'].astype(int)\n",
    "outliers_df['percentage'] = outliers_df['percentage'].round(2)\n",
    "display(outliers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd01460-ec23-4452-b75a-ea7528e51d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c0b93-82ee-4d1b-98b4-d991ded1363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gistogram \n",
    "vars_list=['DV_R', 'DA_R', 'AV_R', 'AA_R', 'PM_R'] \n",
    "\n",
    "plt.figure(figsize=[20, 4])\n",
    "for i, col in enumerate(vars_list): \n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    n, bins, patches = plt.hist(df[col], bins = 10)\n",
    "    plt.title(col)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3d01e-6c4e-4a70-84e8-fe1e18d9b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corr Analysis\n",
    "corr = df[['DV_R', 'DA_R', 'AV_R', 'AA_R', 'PM_R', 'FIN_JGMT']].corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr,annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1faba11-058d-450a-a9b7-ae6d8af5040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['DV_R', 'DA_R', 'AV_R', 'AA_R', 'PM_R']]\n",
    "y = df['FIN_JGMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942a381-3a93-4e43-894c-79cb3cced3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=0, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e454ee-c2cd-416c-b37a-3c85ebcc0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer, QuantileTransformer \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa052b5-8fc2-4601-94fa-297c66955815",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizers = {\n",
    "    'StandardScaler': StandardScaler(), \n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(), \n",
    "    'Normalizer': Normalizer(), \n",
    "    'QuantileTranformer': QuantileTransformer(output_distribution='normal')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ccea1-b4f3-4406-a34a-bab37afa9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab666f-0385-49b7-a56b-951ae0a60816",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, normalizer in normalizers.items(): \n",
    "    X_train_normalized = normalizer.fit_transform(X_train)\n",
    "    X_test_normalized = normalizer.transform(X_test)\n",
    "\n",
    "    # Save normalize data \n",
    "    scaled_data[name] = {\n",
    "        'X_train': X_train_normalized, \n",
    "        'X_test': X_test_normalized, \n",
    "        'normalizer': normalizer\n",
    "    }\n",
    "    print(f\"Applied {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc138c56-327f-4f94-b4d5-2e29f4cda430",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = min(1000, len(X_train))\n",
    "sample_indices = np.random.choice(len(X_train), sample_size, replace=False)\n",
    "\n",
    "# create figure \n",
    "n_features = X_train.shape[1]\n",
    "n_normalizers = len(normalizers) + 1 #for original data\n",
    "fig_height = 4 * n_features\n",
    "fig_width = 3 * n_normalizers\n",
    "plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "# visual\n",
    "for i, feature_idx in enumerate(range(X_train.shape[1])): \n",
    "    feature_name = X.columns[feature_idx]\n",
    "\n",
    "    plt.subplot(n_features, n_normalizers, i * n_normalizers + 1)\n",
    "    sns.histplot(X_train.iloc[sample_indices, feature_idx], kde=True, color = 'navy')\n",
    "    plt.title(f'Original: {feature_name}', fontsize=10)\n",
    "    plt.xlabel('')\n",
    "    # normolize data \n",
    "    for j, (name, data) in enumerate(scaled_data.items()): \n",
    "        plt.subplot(n_features, n_normalizers, i* n_normalizers + j + 2)\n",
    "        sns.histplot(data['X_train'][sample_indices, feature_idx], kde=True, color='darkgreen')\n",
    "        plt.title(f'{name}: {feature_name}', fontsize=10)\n",
    "        plt.xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cec51b-18c0-4c2c-a090-938053c8f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Comparing normalization methods using baseline model:\")\n",
    "\n",
    "normalization_results = {} \n",
    "\n",
    "for name, data in scaled_data.items(): \n",
    "    model = LogisticRegression(random_state=0, max_iter=1000, C=1.0, solver='liblinear')\n",
    "    model.fit(data['X_train'], y_train)\n",
    "\n",
    "    y_pred = model.predict(data['X_test'])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    normalization_results[name] = {\n",
    "        'accuracy': accuracy, \n",
    "        'report': report, \n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "    print(f\"{name}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Visualization of comparison of normalization methods \n",
    "plt.figure(figsize=[12, 6])\n",
    "accuracies =[result['accuracy'] for result in normalization_results.values()]\n",
    "method_names = list(normalization_results.keys())\n",
    "\n",
    "sns.barplot(x=method_names, y=accuracies)\n",
    "plt.title('Comparison of Normalization Methods')\n",
    "plt.xlabel(\"Normalization Method\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adding Precision Values\n",
    "for i, acc in enumerate(accuracies): \n",
    "    plt.text (i, acc + 0.01, f'{acc:.4f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900e34c-e691-4ab7-bd70-6ad7c241b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_method = max(normalization_results.items(), key = lambda x: x[1]['accuracy'])[0]\n",
    "best_normalizer = scaled_data[best_method]['normalizer']\n",
    "X_train_scaled = scaled_data[best_method]['X_train']\n",
    "X_test_scaled = scaled_data[best_method]['X_test']\n",
    "\n",
    "print(f\"\\nBest normalization method: {best_method} with accuracy {normalization_results[best_method]['accuracy']:.4f}\")\n",
    "print(\"Using this method for further analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f62397-eaea-42ce-89b4-78caa4746a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with StandardScaler\n",
    "print(f'Training set size: {X_train.shape[0]} rows')\n",
    "print(f\"Test set size: {X_test.shape[0]} rows\")\n",
    "print(f\"\\nClass distribution in training set: {pd.Series(y_train).value_counts().to_dict()}\")\n",
    "print(f\"Class distribution in test set: {pd.Series(y_test).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50a04d9-2845-41fd-8430-e5ea11094bf6",
   "metadata": {},
   "source": [
    "### Baseline Model (Before balancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029cb1f-cf77-4520-9252-35543843729f",
   "metadata": {},
   "source": [
    "#### Training and evaluating baseline model on imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab4e9a3-325f-4520-85c2-3d79c0b84877",
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_weight = 5\n",
    "major_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd5bdc-7256-4b55-b45e-8317c9521652",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = LogisticRegression(random_state=42, \n",
    "                                   max_iter=1000, \n",
    "                                   C=1.0,\n",
    "                                    solver='liblinear', \n",
    "                                   class_weight={0: minor_weight, 1: major_weight})\n",
    "print(f\"Baseline model with class weigh: minor={minor_weight}, major={major_weight}\")\n",
    "baseline_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82ca9c-ef28-4cd0-8b91-46a040648b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_baseline = baseline_model.predict(X_test_scaled)\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "baseline_report = classification_report(y_test, y_pred_baseline, output_dict=True)\n",
    "baseline_conf_matrix = confusion_matrix(y_test, y_pred_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a7f37-27b3-4691-a6e6-abf894aa32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = baseline_model.predict_proba(X_test_scaled)[:, 1]\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cadae8-3ddc-47fb-86be-47d79317d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainset scoring\n",
    "train_pred = baseline_model.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, train_pred)\n",
    "train_report = classification_report(y_train, train_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf6567-c59b-4e25-b259-e0a7ed26115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainset ROC-AUC\n",
    "train_proba = baseline_model.predict_proba(X_train_scaled)[:, 1]\n",
    "train_fpr, train_tpr, _ = roc_curve(y_train, train_proba)\n",
    "train_roc_auc = auc(train_fpr, train_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33e8dd-fb4e-49ca-9442-66c75479d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTestset results:\")\n",
    "print(f\"Accuracy: {baseline_accuracy:.4f}\")\n",
    "print(f\"F1 (class 0): {baseline_report['0']['f1-score']:.4f}\")\n",
    "print(f\"F1 (class 1): {baseline_report['1']['f1-score']:.4f}\")\n",
    "print(f\"ROC-AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61827a35-183c-4210-ae4f-4869146b8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC-AUC = {test_roc_auc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-AUC baseline model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b3578-679a-4674-9b06-02eee8a3c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result comparison Train and Test\n",
    "results_comparison = pd.DataFrame({\n",
    "    \"Metrics\" : ['Accuracy', 'F1 (class 0)', 'F1 (class 1)', 'ROC-AUC'],\n",
    "    'Trainset' : [train_accuracy, train_report['0']['f1-score'], \n",
    "                 train_report['1']['f1-score'], train_roc_auc], \n",
    "    'Testset' : [baseline_accuracy, baseline_report['0']['f1-score'], \n",
    "                baseline_report['1']['f1-score'], test_roc_auc]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce64c0-eb0d-4606-88c2-d89643f158ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTrainset nd Testset results:\")\n",
    "print(results_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390026e2-e945-48b2-81c6-ae3d9d7c9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "results_comparison.set_index('Metrics').plot(kind='bar')\n",
    "plt.title('Metrix Trainset and Testset')\n",
    "plt.ylabel('Mean')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.grid(axis='y')\n",
    "plt.legend(title='')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0222a-3ae1-4755-8364-dc41f1c7ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of confusion matrix for baseline model\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(baseline_conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=['Defect (0)', 'Normal (1)'],\n",
    "           yticklabels=['Defect (0)', 'Normal (1)'])\n",
    "plt.title('Confusion Matrix: Baseline Model (No Balancing)')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b4e48-84a9-4428-a73a-3f53335c1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR curve for baseline model\n",
    "precision_baseline, recall_baseline, _ = precision_recall_curve(y_test, y_proba_baseline)\n",
    "pr_auc_baseline = average_precision_score(y_test, y_proba_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e7de4-32cb-4c6c-a648-34b89279b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_baseline, precision_baseline, label=f'Baseline PR (AP = {pr_auc_baseline:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('PR Curve for Baseline Model (No Balancing)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415455e7-ab06-4d01-9234-83fb91148571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for baseline model\n",
    "baseline_coef = baseline_model.coef_[0]\n",
    "baseline_feature_importance = pd.DataFrame({'Feature': ['DV_R', 'DA_R', 'AV_R', 'AA_R', 'PM_R'], \n",
    "                                          'Coefficient': baseline_coef})\n",
    "baseline_feature_importance = baseline_feature_importance.sort_values('Coefficient', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=baseline_feature_importance)\n",
    "plt.title('Baseline Model (Logistic Regression) Coefficients')\n",
    "plt.axvline(x=0, color='gray', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5575787-812a-4ee3-b598-80c0100a6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation of baseline coefficients\n",
    "print(\"\\nInterpretation of baseline model coefficients:\")\n",
    "for feature, coef_value in zip(baseline_feature_importance['Feature'], baseline_feature_importance['Coefficient']):\n",
    "    effect = \"positively\" if coef_value > 0 else \"negatively\"\n",
    "    print(f\"- {feature}: {coef_value:.4f} - {effect} affects the probability of normal welding quality\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1d276-b403-409c-8ecf-89eb6b7be407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store baseline results for later comparison\n",
    "baseline_results = {\n",
    "    'accuracy': baseline_accuracy,\n",
    "    'report': baseline_report,\n",
    "    'conf_matrix': baseline_conf_matrix,\n",
    "    'fpr': fpr_baseline,\n",
    "    'tpr': tpr_baseline,\n",
    "    'roc_auc': roc_auc_baseline,\n",
    "    'precision': precision_baseline,\n",
    "    'recall': recall_baseline,\n",
    "    'pr_auc': pr_auc_baseline,\n",
    "    'model': baseline_model\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec35a6c-0e07-4ba8-87fd-525cc954044f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
